{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import spacy\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import io\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check if cuda is available\n",
    "cuda = torch.cuda.is_available()\n",
    "print('CUDA is', cuda)\n",
    "\n",
    "num_workers = 8 if cuda else 0\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('../Data/glove.6B.50d.txt', 'r', encoding='utf8') as f:\n",
    "    glove_file = f.read()\n",
    "    \n",
    "glove_sentences = glove_file.splitlines()\n",
    "glove_vocab = {}\n",
    "for sentence in glove_sentences:\n",
    "    word = sentence.split()[0]\n",
    "    embedding = np.array(sentence.split()[1:], dtype = float)\n",
    "    glove_vocab[word] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../Data/furniture_cleaned-tagged_m.json',) \n",
    "data = json.load(f)\n",
    "\n",
    "#CALCULATING AMBIGUITY SCORES IN IS ADJECTIVES\n",
    "ambiguity_m = {}\n",
    "for element in data[-1]:\n",
    "    if element[3] == 'a':\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1\n",
    "    ambiguity_m[element[0]] = [element[2], score]\n",
    "    \n",
    "    \n",
    "f = open('../Data/furniture_cleaned-tagged_a.json',) \n",
    "data = json.load(f)\n",
    "\n",
    "#CALCULATING AMBIGUITY SCORES IN IS ADJECTIVES\n",
    "ambiguity_a = {}\n",
    "for element in data[-1]:\n",
    "    if element[3] == 'a':\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1\n",
    "    ambiguity_a[element[0]] = [element[2], score]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GIVING PREFERENCE TO AKSHAT'S LABELS. REVERSE THE ORDER TO GIVE PREFERENCE TO MANUEL'S LABELS\n",
    "ambiguity = {}\n",
    "\n",
    "for adj in ambiguity_a:\n",
    "    if ambiguity_a[adj] !=0 and adj in glove_vocab:\n",
    "        ambiguity[adj] = ambiguity_a[adj][1]\n",
    "        \n",
    "for adj in ambiguity_m:\n",
    "    if ambiguity_m[adj] !=0 and adj not in ambiguity and adj in glove_vocab:\n",
    "        ambiguity[adj] = ambiguity_m[adj][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for adj in ambiguity:\n",
    "    all_data.append([glove_vocab[adj], ambiguity[adj]])\n",
    "    \n",
    "random.shuffle(all_data)\n",
    "size = len(all_data)\n",
    "training_data = all_data[:int(size*0.9)]\n",
    "test_data = all_data[int(size*0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        return torch.from_numpy(self.X[index][0]).float(), self.X[index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "train_dataset = MyDataset(training_data)\n",
    "train_loader = DataLoader(train_dataset, shuffle = True, batch_size = batch_size)\n",
    "\n",
    "test_dataset = MyDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_MLP_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_MLP_Model, self).__init__()\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(50)\n",
    "        self.fc1 = nn.Linear(50, 128)\n",
    "        \n",
    "        #self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(128, 8)\n",
    "        \n",
    "        #self.batchnorm3 = nn.BatchNorm1d(32)\n",
    "        #self.fc3 = nn.Linear(32, 8)\n",
    "        \n",
    "        #self.batchnorm_last = nn.BatchNorm1d(8)\n",
    "        self.fc_last = nn.Linear(8, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.batchnorm1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #x = self.batchnorm2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        #x = self.batchnorm3(x)\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        \n",
    "        #x = self.batchnorm_last(x)\n",
    "        x = self.fc_last(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')  \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, validate_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(validate_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(validate_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.6910996456940969 Time:  0.18021798133850098 s\n",
      "Testing Loss:  0.6602045595645905\n",
      "Testing Accuracy:  67.5 %\n",
      "====================\n",
      "Training Loss:  0.5768260634607739 Time:  0.1516423225402832 s\n",
      "Testing Loss:  0.6029305189847947\n",
      "Testing Accuracy:  66.25 %\n",
      "====================\n",
      "Training Loss:  0.5077319701512655 Time:  0.17156195640563965 s\n",
      "Testing Loss:  0.5970222055912018\n",
      "Testing Accuracy:  71.25 %\n",
      "====================\n",
      "Training Loss:  0.47853511687782074 Time:  0.22916913032531738 s\n",
      "Testing Loss:  0.6012938678264618\n",
      "Testing Accuracy:  72.5 %\n",
      "====================\n",
      "Training Loss:  0.45412671259707876 Time:  0.16925406455993652 s\n",
      "Testing Loss:  0.6081951022148132\n",
      "Testing Accuracy:  68.75 %\n",
      "====================\n",
      "Training Loss:  0.42786228044165503 Time:  0.19726204872131348 s\n",
      "Testing Loss:  0.6110174238681794\n",
      "Testing Accuracy:  70.0 %\n",
      "====================\n",
      "Training Loss:  0.4029181234538555 Time:  0.12730121612548828 s\n",
      "Testing Loss:  0.6284371584653854\n",
      "Testing Accuracy:  65.0 %\n",
      "====================\n",
      "Training Loss:  0.37369384202692246 Time:  0.15577125549316406 s\n",
      "Testing Loss:  0.6692878693342209\n",
      "Testing Accuracy:  70.0 %\n",
      "====================\n",
      "Training Loss:  0.34197492483589387 Time:  0.15775108337402344 s\n",
      "Testing Loss:  0.6945820346474647\n",
      "Testing Accuracy:  68.75 %\n",
      "====================\n",
      "Training Loss:  0.306858721954955 Time:  0.1811230182647705 s\n",
      "Testing Loss:  0.7531885147094727\n",
      "Testing Accuracy:  67.5 %\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "model = My_MLP_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for i in range(10):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = validate_model(model, test_loader, criterion)\n",
    "\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
